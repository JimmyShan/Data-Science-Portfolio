{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data scrapping\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script collects data from 'www.apartments.com' and store them into a DataFrame. The following data are collected from the website. Later, data cleaning is performed to remove any unwanted features from the dataframe.\n",
    "- Apartment complex name\n",
    "- Address\n",
    "- Rent\n",
    "- Number of bedroom, bathroom, sqft\n",
    "- Tenant rating\n",
    "- Amenity such as laundary, fitness, business center, etc\n",
    "- Allowed pet\n",
    "- Nearby school\n",
    "- and additional information such as built year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import useful libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# regulate frequency of request\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing the main page with BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The website provides a main page for each of 5 boroughs of NY or any region in general. These main pages can be accessed by urls in the form of 'www.apartment.com/name-of-region'. In this project, 5 boroughs of NY is considered.\n",
    "\n",
    "As a first step, the main page for each borough is parsed to find the total number of 'listing pages' to scrap. The number of listing pages are stored in a dictionary called 'boroughs_max_pages'\n",
    "\n",
    "In order to avoid any problem with the server, 1 second of delay is introduced between each request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'queens-ny': 28, 'manhattan-ny': 28, 'brooklyn-ny': 28, 'bronx-ny': 28, 'staten-island-ny': 23}\n"
     ]
    }
   ],
   "source": [
    "# boroughs of NY\n",
    "boroughs = ['manhattan-ny','queens-ny','brooklyn-ny','staten-island-ny','bronx-ny']\n",
    "boroughs_max_page = {'manhattan-ny':0,'queens-ny':0,'brooklyn-ny':0,'staten-island-ny':0,'bronx-ny':0}\n",
    "boroughs_listing_pages = {'manhattan-ny':{},'queens-ny':{},'brooklyn-ny':{},'staten-island-ny':{},'bronx-ny':{}}\n",
    "\n",
    "# send user agent to avoid bot check\n",
    "headers = {'User-Agent': 'User'}\n",
    "\n",
    "# loop over borooughs of NY\n",
    "for br in boroughs:\n",
    "    \n",
    "    # request page\n",
    "    page_main = requests.get('https://www.apartments.com/%s/'%br, headers=headers)\n",
    "    \n",
    "    # pause to regulate request frequency\n",
    "    time.sleep(1)\n",
    "\n",
    "    # create soup of the main page\n",
    "    soup_main = BeautifulSoup(page_main.content,'html.parser')\n",
    "    \n",
    "    # find the total number of apartment \"listing pages\" to scrap\n",
    "    max_list_pages = 0\n",
    "\n",
    "    # find tag that links to \"listing pages\"\n",
    "    for tag in soup_main.find_all('a'):\n",
    "        # selecting tags containing page numbers\n",
    "        if 'data-page' in tag.attrs:\n",
    "            if not 'class' in tag.attrs:\n",
    "                # found the page numbers to scrap for this br\n",
    "                boroughs_max_page[br] = max(int(tag['data-page']),max_list_pages)\n",
    "\n",
    "# for testing            \n",
    "print(boroughs_max_page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect URLs of each rental listing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing the total number of listing pages to parse for each borough, the listing pages are parsed to collect URLs of apartment listings. The URLs and titles of apartment complex are stored in a dictionary \"boroughs_listing_pages\".\n",
    "\n",
    "Similar to the previous step, 1 second of delay is introduced to avoid any conflict with the server. Because of the delay, it could take a few minuts to run this code. Hence, debug message is printed before looping over each page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collected links to each apartment pages\n"
     ]
    }
   ],
   "source": [
    "# loop over boroughs\n",
    "for br in boroughs:\n",
    "#if True:\n",
    "\n",
    "    # loop over page number\n",
    "    for i in range(boroughs_max_page[br]):\n",
    "        \n",
    "        # set page number to avoid confusion\n",
    "        page_number = i+1\n",
    "        \n",
    "        #print(\"Loop over page %s of %s\" %(page_number,br))\n",
    "        \n",
    "        # request list page\n",
    "        page_listing = requests.get('https://www.apartments.com/%s/%s' %(br,page_number), headers=headers)\n",
    "        \n",
    "        # pause to regulate request frequency\n",
    "        time.sleep(1)\n",
    "       \n",
    "        # parse listing page with BeautifulSoup\n",
    "        soup_listing = BeautifulSoup(page_listing.content,'html.parser')\n",
    "       \n",
    "        # for testing\n",
    "        #print(soup_listing.prettify())\n",
    "\n",
    "        for tag in soup_listing.findAll(\"a\",{\"class\":\"placardTitle\"}):\n",
    "            \n",
    "            # add title and the link to each property\n",
    "            if not tag['title'] in boroughs_listing_pages[br]:\n",
    "                boroughs_listing_pages[br][tag['title']] = tag['href']\n",
    "            \n",
    "# Collected links\n",
    "print(\"collected links to each apartment pages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For debugging purpose, total number of apartment rental listing collected are printed here. In the current state, each borough has around 500 to 700 apartment listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "693\n",
      "666\n",
      "698\n",
      "555\n",
      "659\n"
     ]
    }
   ],
   "source": [
    "# for dibugging\n",
    "for br in boroughs:\n",
    "    print(len(boroughs_listing_pages[br]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Scrap apartment rental listing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous step, we collected title and URL of all apartment rental listing posted on the website. Now, we loop over each URL, and collect useful features such as rent price, number of bedrooms, etc.\n",
    "\n",
    "Parsing is done with BeautifulSoup, and features collected from each apartment rental listing are stored as python list. Later, the lists are converted into a dataframe.\n",
    "\n",
    "\n",
    "Additional care was given so that if some features are missing from an apartment listing, it would not cause the script to crash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define lists to hold contents before creating DataFrame\n",
    "list_rental_title = []\n",
    "list_street_address = []\n",
    "list_city = []\n",
    "list_state = []\n",
    "list_postal_code = []\n",
    "list_rating = []\n",
    "list_amenty = []\n",
    "list_pet_policy = []\n",
    "list_property_info = []\n",
    "list_school = []\n",
    "list_bedrooms = []\n",
    "list_bathrooms = []\n",
    "list_rent = []\n",
    "list_deposit = []\n",
    "list_unit = []\n",
    "list_sqft = []\n",
    "list_name = []\n",
    "list_leaseLength = []\n",
    "list_borough = []\n",
    "\n",
    "# loop over boroughs again to scrap rental listing\n",
    "for br in boroughs:\n",
    "    \n",
    "    # loop over rental listing\n",
    "    for title, url in boroughs_listing_pages[br].items():\n",
    "        \n",
    "        #print(\"boroughs: %s, processing apartment: %s\" %(br,title))\n",
    "        \n",
    "        #=======================================\n",
    "        # request and parse each complex\n",
    "        #=======================================\n",
    "        \n",
    "        # get url from the list\n",
    "        rental_url = url\n",
    "        \n",
    "        # request list page\n",
    "        page_rent = requests.get('%s' %rental_url, headers=headers)\n",
    "        \n",
    "        # pause to regulate request frequency\n",
    "        time.sleep(0.2)\n",
    "        \n",
    "        # parse listing page with BeautifulSoup\n",
    "        soup_rent = BeautifulSoup(page_rent.content,'html.parser')\n",
    "        \n",
    "        # for testing\n",
    "        #print(soup_rent.prettify())\n",
    "        \n",
    "        #=======================================\n",
    "        # find complex's property\n",
    "        #=======================================\n",
    "        \n",
    "        # get rental title\n",
    "        rental_title = title\n",
    "        \n",
    "        # street address\n",
    "        if soup_rent.findAll(\"span\",{\"itemprop\":\"streetAddress\"}):\n",
    "            street_address = soup_rent.findAll(\"span\",{\"itemprop\":\"streetAddress\"})[0].text\n",
    "        else:\n",
    "            street_address = \"\"\n",
    "        \n",
    "        # city\n",
    "        if soup_rent.findAll(\"span\",{\"itemprop\":\"addressLocality\"}):\n",
    "            city = soup_rent.findAll(\"span\",{\"itemprop\":\"addressLocality\"})[0].text\n",
    "        else:\n",
    "            city = \"\"\n",
    "        \n",
    "        # state\n",
    "        if soup_rent.findAll(\"span\",{\"itemprop\":\"addressRegion\"}):\n",
    "            state = soup_rent.findAll(\"span\",{\"itemprop\":\"addressRegion\"})[0].text\n",
    "        else:\n",
    "            state = \"\"\n",
    "        \n",
    "        # postal code (zip code)\n",
    "        if soup_rent.findAll(\"span\",{\"itemprop\":\"postalCode\"}):\n",
    "            postal_code = soup_rent.findAll(\"span\",{\"itemprop\":\"postalCode\"})[0].text\n",
    "        else:\n",
    "            postal_code = \"\"\n",
    "        \n",
    "        # apartment rating\n",
    "        if 'title' in soup_rent.findAll(\"div\",{\"class\":\"rating\"})[0].attrs:\n",
    "            rating = soup_rent.findAll(\"div\",{\"class\":\"rating\"})[0]['title']\n",
    "        else:\n",
    "            rating = \"\"\n",
    "        \n",
    "        # list of amenties\n",
    "        amenty_temp = []\n",
    "        if soup_rent.findAll(\"section\",{\"class\":\"printPropertySection\"}):\n",
    "            for tag_amenty in soup_rent.findAll(\"section\",{\"class\":\"printPropertySection\"})[0].findAll(\"li\"):\n",
    "                amenty_temp.append(tag_amenty.text)\n",
    "            \n",
    "        # add amenty to row\n",
    "        amenty = amenty_temp\n",
    "        \n",
    "        # pet policy\n",
    "        pet_policy_temp = []\n",
    "        for tags_pet in soup_rent.findAll(\"div\",{\"class\":\"petPolicyDetails\"}):\n",
    "            pet_policy_temp.append(tags_pet.text)\n",
    "            \n",
    "        # add pet policy to row\n",
    "        pet_policy = pet_policy_temp\n",
    "            \n",
    "        # additional information such as built date, complex size    \n",
    "        if soup_rent.findAll(\"div\",{\"class\":\"specList propertyFeatures js-spec\"}):\n",
    "            property_info = soup_rent.findAll(\"div\",{\"class\":\"specList propertyFeatures js-spec\"})[0].text\n",
    "        else:\n",
    "            property_info = \"\"\n",
    "        \n",
    "        # nearby school information\n",
    "        school_temp = []\n",
    "        for tag_school in soup_rent.findAll(\"div\",{\"class\":\"schoolCard\"}):\n",
    "            # get name, number of students, rating\n",
    "            school_name = tag_school.findAll(\"p\",{\"class\":\"schoolType\"})[0].text\n",
    "            school_number_student = tag_school.findAll(\"p\",{\"class\":\"numberOfStudents\"})[0].text\n",
    "            school_rating = tag_school.findAll(\"i\")[0]['class'][0]\n",
    "            \n",
    "            # add it to list of schools as a dictionary\n",
    "            school_temp.append({\"school_name\":school_name, \"school_number_student\":school_number_student,\"school_rating\":school_rating})\n",
    "            \n",
    "        # add school to row\n",
    "        school = school_temp\n",
    "\n",
    "        # loop over available units in this apartment\n",
    "        for tag_unit in soup_rent.findAll(\"tr\",{\"class\":\"rentalGridRow\"}):\n",
    "        \n",
    "            #=======================================\n",
    "            # find unit property\n",
    "            #=======================================\n",
    "          \n",
    "            # append complex's properties\n",
    "            list_rental_title.append(rental_title)\n",
    "            list_street_address.append(street_address)\n",
    "            list_city.append(city)\n",
    "            list_state.append(state)\n",
    "            list_postal_code.append(postal_code)\n",
    "            list_rating.append(rating)\n",
    "            list_amenty.append(amenty)\n",
    "            list_pet_policy.append(pet_policy)\n",
    "            list_property_info.append(property_info)\n",
    "            list_school.append(school)\n",
    "            list_borough.append(br)\n",
    "            \n",
    "            # number of bedrooms in this apartment\n",
    "            if tag_unit.findAll(\"td\",{\"class\":\"beds\"}):\n",
    "                list_bedrooms.append(tag_unit.findAll(\"td\",{\"class\":\"beds\"})[0].findAll(\"span\",{\"class\":\"shortText\"})[0].text.strip())\n",
    "            else:\n",
    "                list_bedrooms.append(\"\")\n",
    "            \n",
    "            # number of bathroom in this apartment\n",
    "            if tag_unit.findAll(\"td\",{\"class\":\"baths\"}):\n",
    "                list_bathrooms.append(tag_unit.findAll(\"td\",{\"class\":\"baths\"})[0].findAll(\"span\",{\"class\":\"shortText\"})[0].text.strip())\n",
    "            else:\n",
    "                list_bathrooms.append(\"\")\n",
    "            \n",
    "            # rent per month\n",
    "            if tag_unit.findAll(\"td\",{\"class\":\"rent\"}):\n",
    "                list_rent.append(tag_unit.findAll(\"td\",{\"class\":\"rent\"})[0].text.strip())\n",
    "            else:\n",
    "                list_rent.append(\"\")\n",
    "            \n",
    "            # deposit\n",
    "            if tag_unit.findAll(\"td\",{\"class\":\"deposite\"}):\n",
    "                list_deposit.append(tag_unit.findAll(\"td\",{\"class\":\"deposit\"})[0].text.strip())\n",
    "            else:\n",
    "                list_deposit.append(\"\")\n",
    "            \n",
    "            # unit\n",
    "            if tag_unit.findAll(\"td\",{\"class\":\"unit\"}):\n",
    "                list_unit.append(tag_unit.findAll(\"td\",{\"class\":\"unit\"})[0].text.strip())\n",
    "            else:\n",
    "                list_unit.append(\"\")\n",
    "        \n",
    "            # sqft\n",
    "            if tag_unit.findAll(\"td\",{\"class\":\"sqft\"}):\n",
    "                list_sqft.append(tag_unit.findAll(\"td\",{\"class\":\"sqft\"})[0].text.strip())\n",
    "            else:\n",
    "                list_sqft.append(\"\")\n",
    "        \n",
    "            # name\n",
    "            if tag_unit.findAll(\"td\",{\"class\":\"name\"}):\n",
    "                list_name.append(tag_unit.findAll(\"td\",{\"class\":\"name\"})[0].text.strip())\n",
    "            else:\n",
    "                list_name.append(\"\")\n",
    "                \n",
    "            # lease length\n",
    "            if tag_unit.findAll(\"td\",{\"class\":\"leaseLength\"}):\n",
    "                list_leaseLength.append(tag_unit.findAll(\"td\",{\"class\":\"leaseLength\"})[0].text.strip())\n",
    "            else:\n",
    "                list_leaseLength.append(\"\")\n",
    "            \n",
    "                    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting list to DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lists collected from the previous step are converted into a DataFrame. The DataFrame is then saved as csv for post-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'rental_title':list_rental_title,\n",
    "                   'borough':list_borough,\n",
    "                   'street_address':list_street_address,\n",
    "                   'city':list_city,\n",
    "                   'state':list_state,\n",
    "                   'postal_code':list_postal_code,\n",
    "                   'rating':list_rating,\n",
    "                   'amenty':list_amenty,\n",
    "                   'pet_policy':list_pet_policy,\n",
    "                   'property_info':list_property_info,\n",
    "                   'school':list_school,\n",
    "                   'bedrooms':list_bedrooms,\n",
    "                   'bathrooms':list_bathrooms,\n",
    "                   'rent':list_rent,\n",
    "                   'deposit':list_deposit,\n",
    "                   'unit':list_unit,\n",
    "                   'sqft':list_sqft,\n",
    "                   'name':list_name,\n",
    "                   'leaseLength':list_leaseLength})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before store the DataFrame to csv, check the output and make sure it looks okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv('ny_rental_data.csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
